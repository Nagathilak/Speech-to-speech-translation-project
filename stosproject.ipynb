{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397f26f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTS in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (2.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from gTTS) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from gTTS) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2025.4.26)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from SpeechRecognition) (4.13.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: translate in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from translate) (8.1.8)\n",
      "Requirement already satisfied: lxml in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from translate) (5.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from translate) (2.32.3)\n",
      "Requirement already satisfied: libretranslatepy==2.1.1 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from translate) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from click->translate) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests->translate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests->translate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests->translate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thilak\\desktop\\proj1\\.venv\\lib\\site-packages (from requests->translate) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS\n",
    "!pip install SpeechRecognition\n",
    "!pip install pydub\n",
    "!pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce05739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thilak\\Desktop\\Proj1\\.venv\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from translate import Translator\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6856610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(input_mp3, output_wav):\n",
    "    audio = AudioSegment.from_mp3(input_mp3)\n",
    "    audio.export(output_wav, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012f8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    try:\n",
    "        recognized_text = recognizer.recognize_google(audio_data)\n",
    "        return recognized_text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from Google's Speech Recognition API; {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac359f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, target_language):\n",
    "    if text is not None:\n",
    "        translator = Translator(to_lang=target_language)\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    else:\n",
    "        return \"No text to translate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11803db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_speech(text, lang_code, output_path):\n",
    "    if text != \"No text to translate\":\n",
    "        tts = gTTS(text=text, lang=lang_code)\n",
    "        tts.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dddc1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_speech_pipeline(input_mp3, output_mp3, target_language='hi'):\n",
    "    # Step 1: Convert MP3 to WAV\n",
    "    wav_file = \"temp_speech.wav\"\n",
    "    convert_mp3_to_wav(input_mp3, wav_file)\n",
    "\n",
    "    # Step 2: Recognize Speech\n",
    "    recognized_text = recognize_speech(wav_file)\n",
    "    print(\"Recognized Speech:\")\n",
    "    print(recognized_text)\n",
    "\n",
    "    # Step 3: Translate Recognized Text\n",
    "    translated_text = translate_text(recognized_text, target_language)\n",
    "    print(\"Translated Text:\")\n",
    "    print(translated_text)\n",
    "\n",
    "    # Step 4: Convert Translated Text to Speech\n",
    "    convert_text_to_speech(translated_text, target_language, output_mp3)\n",
    "    audio = AudioSegment.from_mp3(output_mp3)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0440e7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech_to_speech_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m input_audio_file = \u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mthilak\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mProj1\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mstos.mp3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m output_audio_file = \u001b[33m\"\u001b[39m\u001b[33mtranslated_speech.mp3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mspeech_to_speech_pipeline\u001b[49m(input_audio_file, output_audio_file, target_language=\u001b[33m'\u001b[39m\u001b[33mhi\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'speech_to_speech_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "input_audio_file = \"C:\\\\Users\\\\thilak\\\\Desktop\\\\Proj1\\\\stos.mp3\"\n",
    "\n",
    "output_audio_file = \"translated_speech.mp3\"\n",
    "speech_to_speech_pipeline(input_audio_file, output_audio_file, target_language='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615461ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
